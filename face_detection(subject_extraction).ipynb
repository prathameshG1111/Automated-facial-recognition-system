{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44d156d0-60ca-4ea1-93da-5ae973ca48a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Prathamesh\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from deepface import DeepFace\n",
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8de06146-e529-451f-ac18-901f1f88d15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database connection parameters\n",
    "db_params = {\n",
    "    'dbname': 'College automated reporting system',\n",
    "    'user': 'postgres',\n",
    "    'password': 'Automated@12',\n",
    "    'host': 'localhost',\n",
    "    'port': 5432\n",
    "}\n",
    "\n",
    "# Connect to the PostgreSQL database\n",
    "conn = psycopg2.connect(**db_params)\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11352ca8-4def-4bf2-a3c4-77ef03a00f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preload subject time ranges\n",
    "subject_time_ranges = []\n",
    "\n",
    "def preload_subject_time_ranges():\n",
    "    cursor.execute(sql.SQL('SELECT id, name, \"from_time\", \"to_time\" FROM \"Clg automated\".\"Subject\"'))\n",
    "    rows = cursor.fetchall()\n",
    "    for row in rows:\n",
    "        subject_time_ranges.append({\n",
    "            \"id\": row[0],\n",
    "            \"name\": row[1],\n",
    "            \"from_time\": row[2],\n",
    "            \"to_time\": row[3]\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5adc261c-8afa-4002-95f7-a242eccfd351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subject_id_by_time(time):\n",
    "    for subject in subject_time_ranges:\n",
    "        if subject[\"from_time\"] <= time <= subject[\"to_time\"]:\n",
    "            return subject[\"id\"], subject[\"name\"]\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a56c470-92b1-40bf-98f8-0f57d8d360fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_datetime_from_filename(filename):\n",
    "    return datetime.datetime.strptime(filename, \"%Y%m%d%H%M%S\").time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7347ac48-8dd6-4d43-a11d-2327f87e71f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    if image is not None and image.size != 0:\n",
    "        image = cv2.resize(image, (224, 224))  # VGG-Face expects 224x224 images\n",
    "        image = image / 255.0  # Normalize\n",
    "        return image\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "036b99a0-3ec9-4175-94b2-de326cd7e380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_directory(base_dir):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for person_name in os.listdir(base_dir):\n",
    "        person_dir = os.path.join(base_dir, person_name)\n",
    "        for filename in os.listdir(person_dir):\n",
    "            img_path = os.path.join(person_dir, filename)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is not None:\n",
    "                images.append(img)\n",
    "                labels.append(person_name)\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68593126-0feb-4c29-8316-894aaff71b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_face_embedding(image):\n",
    "    if image is not None:\n",
    "        return DeepFace.represent(img_path=image, model_name=\"VGG-Face\", enforce_detection=False)[0][\"embedding\"]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddbe1539-feab-4644-aeae-6795673f4518",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_face(test_embedding, known_face_encodings, known_face_names):\n",
    "    distances = [np.linalg.norm(test_embedding - known_face_encoding) for known_face_encoding in known_face_encodings]\n",
    "    best_match_index = np.argmin(distances)\n",
    "    if distances[best_match_index] < 0.6:\n",
    "        return known_face_names[best_match_index]\n",
    "    else:\n",
    "        return \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c046e671-919b-44ce-be1a-39547d776ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_attendance(subject_name, subject_id, date, students, image_name, image_path):\n",
    "    if subject_id is None:\n",
    "        print(f\"No subject found for the specified time.\")\n",
    "        return\n",
    "    for student in students:\n",
    "        student_id = get_student_id_by_name(student)\n",
    "        if student_id is None:\n",
    "            print(f\"Student '{student}' not found in the database.\")\n",
    "            continue\n",
    "        cursor.execute(\n",
    "            sql.SQL('INSERT INTO \"Clg automated\".\"Attendance\" (date, subject_id, student_id, image) VALUES (%s, %s, %s, %s)'),\n",
    "            [date, subject_id, student_id, image_path]\n",
    "        )\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3066c28e-ee86-4877-bee8-22e95f9b9dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_student_id_by_name(name):\n",
    "    cursor.execute(sql.SQL('SELECT id FROM \"Clg automated\".\"Student\" WHERE \"Name\" = %s'), [name])\n",
    "    result = cursor.fetchone()\n",
    "    return result[0] if result else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "615a67d4-a16b-4166-97a3-3b68855e6adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_on_mono_faces(test_directory, known_face_encodings, known_face_names):\n",
    "    for filename in os.listdir(test_directory):\n",
    "        test_image_path = os.path.join(test_directory, filename)\n",
    "        test_image = cv2.imread(test_image_path)\n",
    "        test_image_preprocessed = preprocess_image(test_image)\n",
    "        if test_image_preprocessed is not None:\n",
    "            test_embedding = get_face_embedding(test_image_preprocessed)\n",
    "            if test_embedding is not None:\n",
    "                name = recognize_face(test_embedding, known_face_encodings, known_face_names)\n",
    "                plt.imshow(cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB))\n",
    "                plt.title(f\"Recognized person: {name}\")\n",
    "                plt.axis('off')\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3cd6bd9-9a30-4bf4-8e74-065505eaddc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_on_multi_faces(test_directory, known_face_encodings, known_face_names):\n",
    "    for filename in os.listdir(test_directory):\n",
    "        test_image_path = os.path.join(test_directory, filename)\n",
    "        test_image = cv2.imread(test_image_path)\n",
    "        \n",
    "        faces = DeepFace.extract_faces(img_path=test_image_path, detector_backend='opencv', enforce_detection=False)\n",
    "        \n",
    "        plt.imshow(cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB))\n",
    "        ax = plt.gca()\n",
    "        \n",
    "        recognized_names = []\n",
    "        \n",
    "        for face in faces:\n",
    "            facial_area = face['facial_area']\n",
    "            x, y, w, h = facial_area['x'], facial_area['y'], facial_area['w'], facial_area['h']\n",
    "            face_image = test_image[y:y+h, x:x+w]\n",
    "            face_preprocessed = preprocess_image(face_image)\n",
    "            if face_preprocessed is not None:\n",
    "                face_embedding = get_face_embedding(face_preprocessed)\n",
    "                if face_embedding is not None:\n",
    "                    name = recognize_face(face_embedding, known_face_encodings, known_face_names)\n",
    "                    if name != \"Unknown\":\n",
    "                        recognized_names.append(name)\n",
    "                    ax.add_patch(plt.Rectangle((x, y), w, h, edgecolor='red', facecolor='none', linewidth=2))\n",
    "                    plt.text(x, y - 10, name, color='red', fontsize=12, weight='bold')\n",
    "        \n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "        # Extract time from filename and get subject\n",
    "        time = extract_datetime_from_filename(filename.split('.')[0])  # Strip the extension\n",
    "        subject_id, subject_name = get_subject_id_by_time(time)\n",
    "        \n",
    "        if recognized_names and subject_id is not None:\n",
    "            date = datetime.datetime.strptime(filename[:8], \"%Y%m%d\").date()\n",
    "            print(f\"Students {recognized_names} attended {subject_name} on {date}\")\n",
    "            mark_attendance(subject_name, subject_id, date, recognized_names, filename, test_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2eca40c1-11c7-4966-8a62-c412ec963735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training images\n",
    "training_dir = r'C:\\Users\\Prathamesh\\Desktop\\Infosys project\\Image directory\\1. Training images'\n",
    "train_images, train_labels = load_images_from_directory(training_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd63d99a-6c2c-4a07-bba4-d056d1b6e15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess and encode training images\n",
    "known_face_encodings = []\n",
    "known_face_names = []\n",
    "for img, label in zip(train_images, train_labels):\n",
    "    img_preprocessed = preprocess_image(img)\n",
    "    if img_preprocessed is not None:\n",
    "        embedding = get_face_embedding(img_preprocessed)\n",
    "        if embedding is not None:\n",
    "            known_face_encodings.append(np.array(embedding))\n",
    "            known_face_names.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4928a657-9645-407f-903d-eff6a2dead57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on Mono faces\n",
    "mono_face_test_directory = r'C:\\Users\\Prathamesh\\Desktop\\Infosys project\\Image directory\\2. Testing images\\Mono face'\n",
    "test_on_mono_faces(mono_face_test_directory, known_face_encodings, known_face_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a276c8dc-617d-41f7-a124-0a663bc2110f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on Multi faces\n",
    "multi_face_test_directory = r'C:\\Users\\Prathamesh\\Desktop\\Infosys project\\Image directory\\2. Testing images\\Multi face'\n",
    "test_on_multi_faces(multi_face_test_directory, known_face_encodings, known_face_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5038c4c4-76db-4a9a-91b2-7d0c31b805fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the database connection\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdce546-530a-4f92-b985-a4567bf8cbc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
